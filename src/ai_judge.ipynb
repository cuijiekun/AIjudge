{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T13:54:29.663731Z",
     "start_time": "2019-04-02T13:54:27.933255Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import jieba.posseg\n",
    "import pandas as pd\n",
    "\n",
    "import param\n",
    "import util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定义分词函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T14:09:02.708988Z",
     "start_time": "2019-04-02T14:09:02.697112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_word(text, stopwords):\n",
    "    word_list = jieba.cut(text)\n",
    "    start = True\n",
    "    result = ''\n",
    "    for word in word_list:\n",
    "        word = word.strip()\n",
    "        if word not in stopwords:\n",
    "            if start is True:\n",
    "                result = word\n",
    "                start = False\n",
    "            else:\n",
    "                result += ' ' + word\n",
    "    return result.encode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T14:14:40.010376Z",
     "start_time": "2019-04-02T14:14:39.994018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = {}\n",
    "for line in codecs.open(param.data_path+'/input/stop.txt', 'r', 'utf-8'):\n",
    "    stopwords[line.rstrip()] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 加载数据 并分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tr = []\n",
    "for i, line in enumerate(open(param.data_path+'input/train.txt')):\n",
    "    if i % 1000 == 1:\n",
    "        util.log('iter = %d' % i)\n",
    "    segs = line.split('\\t')\n",
    "    row = {}\n",
    "    row['id'] = segs[0]\n",
    "    row['content'] = split_word(segs[1].strip(), stopwords)\n",
    "    row['penalty'] = segs[2]\n",
    "    row['laws'] = segs[3].strip()\n",
    "    df_tr.append(row)\n",
    "    \n",
    "df_tr = pd.DataFrame(df_tr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
